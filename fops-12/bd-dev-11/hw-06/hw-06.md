# Домашнее задание к занятию 6. «Troubleshooting»

## Задача 1
### Задание
Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести эту операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя;
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.

### Ответ
1. Список операций для остановки запроса пользователя:
   1. Выполнить команду: db.currentOp(). Это покажет все текущие операции, которые выполняются в MongoDB.
   2. В выводе поискать идентификатор запроса пользователя (поле "opId"). Вероятно пользователю придется предоставить больше информации о его запросе.
   3. Можем прервать запрос, используя команду: db.killOp(opId), где opId - это идентификатор операции, который мы нашли на предыдущем шаге.

2. Решение проблемы с долгими (зависающими) запросами:
   1. Определить самые часто используемые запросы и убедиться, что они правильно оптимизированы с использованием индексов. Индексы могут существенно ускорить запросы, минимизируя количество данных, которые нужно просканировать.
   2. Ограничить размер возвращаемых данных. Если возможно, возвращать только необходимые поля и использовать операторы, такие как $limit и $skip, чтобы ограничить количество возвращаемых документов.
   3. Использовать горизонтальное масштабирование. Добавить больше узлов к MongoDB-инфраструктуре, чтобы увеличить производительность и снизить время обработки запросов.
   4. В зависимости от приложения, может быть возможно кешировать результаты запросов, чтобы сократить количество одинаковых запросов к базе данных.
   5. Использовать встроенный профилировщик MongoDB, который может помочь выявить медленные запросы и указать на возможные области оптимизации.


## Задача 2
### Задание
Перед выполнением задания познакомьтесь с документацией по [Redis latency troubleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:

- сначала происходит рост отношения записанных значений к истекшим,
- Redis блокирует операции записи.

Как вы думаете, в чём может быть проблема?

### Ответ
Это похоже на максимальное использование памяти Redis. Когда Redis достигает установленной в настройках максимальной памяти, он пытается освободить некоторую память, удаляя ключи с истекшим TTL.
Но, если TTL у ключей еще не истекли или если ключи добавляются быстрее, чем освобождается память, то Redis может войти в состояние, когда достигнут порог максимальной утилизации памяти и больше операции записи не могут быть выполнены.
Это объясняет наблюдаемое поведение: сначала рост соотношения записанных значений к истекшим (так как записи добавляются быстрее, чем удаляются), затем блокировка операций записи при достижении предела использования памяти.
Чтобы исправить эту проблему, придется пересмотреть подход к освобождению памяти Redis или увеличить доступную ему оперативную память. В общем, можно:
- Изменить политику maxmemory-policy Redis на allkeys-lru или volatile-lru, которые будут удалять ключи наиболее давно не использовавшиеся при необходимости освободить память.
- Если на сервере есть доступная память, то увеличить максимальный объем памяти Redis в его настройках.
- Если максимальное значение памяти уже настроено до максимально допустимого, возможно, потребуется масштабироваться горизонтально, добавив еще один узел Redis или перейдя на кластер Redis.
- Рассмотреть возможность оптимизации производительности, например, снижение объема данных, сохраняемых в Redis.

 
## Задача 3
### Задание
Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базы
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```
Как вы думаете, почему это начало происходить и как локализовать проблему?
Какие пути решения этой проблемы вы можете предложить?

### Ответ
Ошибка "Lost connection to MySQL server during query" говорит о том, что существующее соединение с MySQL-сервером потеряно во время выполнения запроса.
Возможные причины:
1. Сам запрос требует слишком много времени для выполнения и сервер разрывает соединение из-за превышения установленного таймаута. Это может произойти, если запрос обрабатывает очень большие объемы данных или набор данных растет с течением времени. 
2. Сервер MySQL недоступен или происходят проблемы со сетью между клиентом и сервером.
3. Отсутствует достаточное количество ресурсов на сервере MySQL, например, ОЗУ или CPU, и по этой причине MySQL вынужден прервать соединение.

Чтобы локализовать проблему, можно выполнить следующие действия:
1. Проверить логи сервера MySQL и клиента. Логи сервера MySQL помогут определить, что именно вызывает потерю соединения.
2. Если причина в длительности запросов, то можно попробовать выполнить такой же запрос непосредственно на сервере базы данных.
3. Если проблемы с ресурсами сервера, такие как недостаток памяти или CPU, то проверить насколько эффективно используются предоставленные ресурсы.
4. Проверить сетевое взаимодействие, пособирать дампы трафика на предмет Retransmission.
   
Пути решения этой проблемы могут включать:
1. Оптимизация запросов с использованием индексов, исключения бесполезных данных или изменение таймаута (например, 'wait_timeout' и 'interactive_timeout'). 
2. Увеличение системных ресурсов, таких как память или CPU, обновление системного/прикладного программного обеспечения или масштабирование сервера базы данных.
3. Если потеря соединения связана с сетевыми проблемами, обратиться к администраторам сети или провайдеру услуги или разобраться самостоятельно.


## Задача 4
### Задание
Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объёмом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:
`postmaster invoked oom-killer`
Как вы думаете, что происходит?
Как бы вы решили эту проблему?

### Ответ
Ошибки "postmaster invoked oom-killer" указывают на то, что процесс "postmaster" вызвал "oom-killer" - механизм ядра Linux, который "убивает" процессы для освобождения оперативной памяти при ее исчерпании.
Сообщение ошибки указывает на связь с PostgreSQL, поскольку "postmaster" - это наименование основного процесса PostgreSQL.
Это означает, что ваш сервер PostgreSQL потребляет слишком много оперативной памяти, что в конечном итоге приводит к перерасходу доступной для сервера памяти и, в свою очередь, вызывает "oom-killer" для того, чтобы освободить некоторую память и предотвратить полное исчерпание ресурсов.

Чтобы решить эту проблему, можно предпринять следующие действия:
1. Оптимизация запросов: долгие или плохо оптимизированные запросы могут потреблять больше памяти. Убедиться, что используются правильные индексы и не происходит ли избыточное количество операций массовой выборки данных или объединения таблиц.
2. Ограничить количество памяти, выделяемое под каждую отдельную сессию, путем установки параметров, таких как: work_mem, maintenance_work_mem, temp_buffers и т.д.
3. Масштабирование: может потребоваться увеличение количества доступной оперативной памяти. При использовании виртуальной машины, часто можно просто добавить больше памяти к работающей ВМ.
4. Также важно обратить внимание на любые внесенные недавно изменения в приложении или базе данных, которые могли привести к увеличению потребления памяти.